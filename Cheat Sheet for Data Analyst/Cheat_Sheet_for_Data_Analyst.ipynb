{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cheat_Sheet_for_Data_Analyst.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Python Toolbox\n",
        "\n",
        "<ul>\n",
        "  <li>Defining a function</li>\n",
        "  <li>Function parameters </li>\n",
        "  <li>Docstrings</li>\n",
        "    <ul>\n",
        "      <li>Docstrings describe what your function does</li>\n",
        "      <li>In between triple double quotes \"\"\"</li>\n",
        "    </ul>\n",
        "  <li>Returning multiple values with <b>Tuples</b></li>\n",
        "    <ul>\n",
        "      <li>Immutable - can’t modify values!</li>\n",
        "      <li>Constructed using parentheses()</li>\n",
        "    </ul>\n",
        "  <li>Scope: global</li>\n",
        "  <li>Nested functions</li>\n",
        "  <li>Using nonlocal</li>\n",
        "    <ul>\n",
        "      <li> The <b>nonlocal</b> keyword is used to work with variables inside nested functions, where the variable should not belong to the inner function.\n",
        "      </li>\n",
        "    </ul>\n",
        "  <li>Add a default argument</li>\n",
        "  <li>Flexible arguments: *args</li>\n",
        "    <ul>\n",
        "      <li> <b>Note!:</b> that args is just a name. You’re not required to use the name args. You can choose any name that you prefer\n",
        "      </li>\n",
        "    </ul>\n",
        "  <li>Flexible arguments: **kwargs</li>\n",
        "    <ul>\n",
        "      <li> works just like *args, but instead of accepting positional arguments it accepts keyword (or named) arguments.\n",
        "      </li>\n",
        "    </ul>\n",
        "  <li>Lambda functions <b>(Anonymous functions)</b></li>\n",
        "    <ul>\n",
        "      <li> Syntax: lambda arguments : expression</li>\n",
        "    </ul>\n",
        "  <li>map Function</li>\n",
        "    <ul>\n",
        "      <li> takes two arguments: map(func, seq)</li>\n",
        "    </ul>\n",
        "  <li>Errors and exceptionsn</li>\n",
        "    <ul>\n",
        "      <li> raise</li>\n",
        "      <li> try</li>\n",
        "      <li> except</li>\n",
        "      <li> finally (optional)</li>\n",
        "    </ul>\n",
        "  <li> Iterators vs. iterables</li>\n",
        "    <ul>\n",
        "      <li> Iterable</li>\n",
        "        <ul>\n",
        "          <li> Examples: lists, strings, dictionaries, file connections</li>\n",
        "          <li> An object with an associated iter() method</li>\n",
        "          <li> Applying iter() to an iterable creates an iterator</li>\n",
        "        </ul>\n",
        "      <li> Iterator</li>\n",
        "        <ul>\n",
        "          <li> Produces next value with next()\n",
        "        </ul>\n",
        "    </ul>\n",
        "  <li> Using enumerate()</li>\n",
        "  <li> Using zip()</li>\n",
        "  <li> Loading data in chunks</li>\n",
        "        <ul>\n",
        "          <li> There can be too much data to hold in memory</li>\n",
        "          <li> Solution:load data in chunks!</li>\n",
        "          <li> Specify the chunk: <code>chunk_size</code></li>\n",
        "        </ul>\n",
        "  <li> A list comprehension</li>\n",
        "  <li> Dict comprehensions</li>\n",
        "  <li> Generator expressions</li>\n",
        "        <ul>\n",
        "         <li>  Generators are iterators, a kind of iterable you can only iterate over once. Generators do not store all the values in memory, <b>they generate the values on the fly</b></li>\n",
        "          <li> Yield</li>\n",
        "        </ul>\n",
        "</ul>\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "t0Ya-W16ifli"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a function\n",
        "def add(): # <- Function header\n",
        "  sum = 2 + 2 # <- Function body\n",
        "  return sum\n",
        "\n",
        "add()\n",
        "\n",
        "# Function parameters\n",
        "def add(para): # <- Function header\n",
        "  sum = para + 2 # <- Function body\n",
        "  return sum\n",
        "\n",
        "add(para)\n",
        "\n",
        "# Docstrings\n",
        "def add(para): # <- Function header\n",
        "  \"\"\"Retrun the sum of para and 2\"\"\"\n",
        "  sum = para + 2 # <- Function body\n",
        "  return sum\n",
        "\n",
        "# Returning multiple values with Tuples\n",
        "def add(para1, para2): # <- Function header\n",
        "  sum1 = para1 + para2 # <- Function body\n",
        "  sum2 = para1 + 2 * para2 \n",
        "  new_tuple = (sum1, sum2)\n",
        "  return new_tuple\n",
        "\n",
        "add(para1, para2)\n",
        "\n",
        "# Scope: global\n",
        "x = 300\n",
        "\n",
        "def myfunc():\n",
        "  x = 200\n",
        "  print(x) # Output 200\n",
        "\n",
        "myfunc()\n",
        "\n",
        "print(x) # Output 300\n",
        "-----------------------\n",
        "x = 300\n",
        "def myfunc():\n",
        "  global x\n",
        "  x = 200\n",
        "\n",
        "myfunc()\n",
        "\n",
        "print(x) # Output 200\n",
        "\n",
        "# Nested function\n",
        "def outer(msg):\n",
        "    # This is the outer enclosing function\n",
        "\n",
        "    def inner():\n",
        "        # This is the nested function\n",
        "        print(msg)\n",
        "\n",
        "    inner()\n",
        "\n",
        "outer(\"Hello\") # Output: Hello\n",
        "\n",
        "# Using nonlocal \n",
        "def outer():\n",
        "  \"\"\"Prints the value of n.\"\"\"    \n",
        "  n = 1\n",
        "\n",
        "  def inner():\n",
        "    nonlocal n\n",
        "    n = 2        \n",
        "    print(n) # Output 2\n",
        "    \n",
        "    inner()\n",
        "    print(n) Output 2\n",
        "\n",
        "outer()\n",
        "\n",
        "# Add a default argument\n",
        "def greet(name, msg=\"Good morning!\"):\n",
        "    \"\"\"\n",
        "    This function greets to\n",
        "    the person with the\n",
        "    provided message.\n",
        "\n",
        "    If the message is not provided,\n",
        "    it defaults to \"Good\n",
        "    morning!\"\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"Hello\", name + ', ' + msg)\n",
        "\n",
        "\n",
        "greet(\"Kate\") # Output: Hello Kate, Good morning!\n",
        "greet(\"Bruce\", \"How do you do?\") # Output: Hello Bruce, How do you do?\n",
        "\n",
        "# Flexible arguments: *args\n",
        "def my_sum(*args):\n",
        "    result = 0\n",
        "    # Iterating over the Python args tuple\n",
        "    for x in args:\n",
        "        result += x\n",
        "    return result\n",
        "\n",
        "print(my_sum(1, 2, 3))\n",
        "\n",
        "# Flexible arguments: **kwargs\n",
        "def concatenate(**kwargs):\n",
        "    result = \"\"\n",
        "    # Iterating over the Python kwargs dictionary\n",
        "    for arg in kwargs.values():\n",
        "        result += arg\n",
        "    return result\n",
        "\n",
        "print(concatenate(a=\"Real\", b=\"Python\", c=\"Is\", d=\"Great\", e=\"!\"))\n",
        "\n",
        "# Lambda functions \n",
        "(lambda x: x + 1)(2) # Output: 3\n",
        "-------\n",
        "raise_to_power = lambda x, y: x ** y\n",
        "raise_to_power(2, 3) # Output: 8\n",
        "\n",
        "# map Function\n",
        "numbers = (1, 2, 3, 4)\n",
        "result = map(lambda x: x + x, numbers)\n",
        "\"\"\"Double all numbers using map and lambda\"\"\"\n",
        "print(list(result))\n",
        "\n",
        "# Errors and exceptions\n",
        "try:\n",
        "\tprint(\"code start\")\n",
        " \n",
        "\tprint(1 / 0) # put unsafe operation in try block\n",
        "\n",
        "\n",
        "except: # if error occur the it goes in except block\n",
        "\tprint(\"an error occurs\")\n",
        "\n",
        "\n",
        "finally: # final code in finally block\n",
        "\tprint(\"Hello world\")\n",
        " \n",
        "# Iterating at once with*\n",
        "word = 'Data'\n",
        "it = iter(word)\n",
        "print(*it) # Output: D a t a\n",
        "\n",
        "# Iterating over dictionaries\n",
        "for key, value in dictName.items():    \n",
        "  print(key, value)\n",
        "\n",
        "# Iterating over file connections\n",
        "file = open('file.txt')\n",
        "it = iter(file)\n",
        "print(next(it)) # Output: First line in the file\n",
        "\n",
        "# Using enumerate()\n",
        "e = enumerate(nameList)\n",
        "e_list = list(e)\n",
        "print(e_list) # Output: [(0, 'firstValue'), (1, 'secondtValue'), (2, 'thirdValue'), (3, 'forthtValue')]\n",
        "\n",
        "for index, value in enumerate(listName):    \n",
        "  print(index, value)\n",
        "\n",
        "for index, value in enumerate(avengers, start=10):    \n",
        "  print(index, value) # Index starts with 10 \n",
        "\n",
        "# Using zip()\n",
        "z = zip(listName1, listName2)\n",
        "print(*z)\n",
        "\n",
        "for z1, z2 in zip(listName1, listName2):    \n",
        "  print(z1, z2)\n",
        "\n",
        "# Loading data in chunks\n",
        "result = []\n",
        "for chunk in pd.read_csv('data.csv', chunksize=1000):    \n",
        "  result.append(sum(chunk['x']))\n",
        "\n",
        "# A list comprehension\n",
        "newlist = [expression for item in iterable if condition == True]\n",
        "\n",
        "fruits = [\"apple\", \"banana\", \"cherry\", \"kiwi\", \"mango\"]\n",
        "\n",
        "newlist = [x for x in fruits if \"a\" in x]\n",
        "\n",
        "print(newlist) # Output: ['apple', 'banana', 'mango']\n",
        "\n",
        "result = [num for num in range(11)]\n",
        "print(result) # Output: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "\n",
        "# Dict comprehensions\n",
        "pos_neg = {num: -num for num in range(9)}\n",
        "print(pos_neg) # Output: {0: 0, 1: -1, 2: -2, 3: -3, 4: -4, 5: -5, 6: -6, 7: -7, 8: -8}\n",
        "\n",
        "# Generator expressions\n",
        "result = (num for num in range(6)) \n",
        "print(list(result)) # Output: [0, 1, 2, 3, 4, 5]\n",
        "\n",
        "# Yield\n",
        "defnum_sequence(n):\n",
        "  \"\"\"Generate values from 0 to n.\"\"\"    \n",
        "  i = 0\n",
        "  while i < n:\n",
        "    yield i        \n",
        "    i += 1\n",
        "\n",
        "result = num_sequence(5)\n",
        "print(type(result)) # Output: <class 'generator'>\n",
        "\n",
        "for item in result:    \n",
        "  print(item) # Output: 0 1 2 3 4 "
      ],
      "metadata": {
        "id": "giyHqr_di5cf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjVA7go5BaYt"
      },
      "source": [
        "## Import Packages and Libraries\n",
        "This is the lineup of the most important Python libraries for data analytics:\n",
        "\n",
        "### Types of Data:\n",
        "\n",
        "<ul>\n",
        "  <li>Flat files</li>\n",
        "    <ul>\n",
        "      <li>txts</li>\n",
        "      <li>csvs</li>\n",
        "    </ul>\n",
        "  <li>Relational databases</li>\n",
        "    <ul>\n",
        "      <li>Microsoft SQL Server</li>\n",
        "      <li>Oracle Database</li>\n",
        "      <li>MySQL</li>\n",
        "      <li>IBM DB2</li>\n",
        "    </ul>\n",
        "  <li>Other file types</li>\n",
        "   <ul>\n",
        "      <li>Excel spreadsheets</li>\n",
        "      <li>MATLAB files</li>\n",
        "      <li>SAS files</li>\n",
        "      <li>Stata files</li>\n",
        "      <li>HDF5 files</li>\n",
        "         <ul>\n",
        "          <li>Hierarchical Data Format version 5</li>\n",
        "          <li>Standard for storing large quantities of numerical data</li>\n",
        "          <li>Data sets can be hundreds of gigabytes or terabytes</li>\n",
        "          <li>HDF5 can scale to exabytes</li>\n",
        "        </ul>\n",
        "      <li>Pickled files</li>\n",
        "         <ul>\n",
        "          <li>File type native to Python</li>\n",
        "          <li>Pickl files are serialized</li>\n",
        "          <li>Serialize = convert object to bytestream</li>\n",
        "        </ul>\n",
        "    </ul>\n",
        "</ul>\n",
        "\n",
        "### Work flow of SQL querying\n",
        "    <ul>\n",
        "      <li>Import packages and functions</li>\n",
        "      <li>Create the data base engine</li>\n",
        "      <li>Connect to the engine</li>\n",
        "      <li>Query the data base</li>\n",
        "      <li>Save query results to a DataFrame</li>\n",
        "      <li>Close the connection</li>\n",
        "    </ul>\n",
        "\n",
        "### Data Processing and Modeling:\n",
        "\n",
        "*   NumPy\n",
        "\n",
        "    <ul>\n",
        "      <li>NumPy arrays: standard for storin gnumerical data</li>\n",
        "      <li>Essential for other packages: e.g. scikit-learn</li>\n",
        "        <ul>\n",
        "          <li>Scikit-learn is a free software machine learning library for the Python programming language.</li>\n",
        "        </ul>\n",
        "    </ul>\n",
        "\n",
        "*   Pandas\n",
        "    <ul>\n",
        "      <li>Exploratory data analysis</li>\n",
        "      <li>Data wrangling</li>\n",
        "      <li>Data preprocessing</li>\n",
        "      <li>Building models</li>\n",
        "      <li>Visualization</li>\n",
        "    </ul>\n",
        "\n",
        "### Data Visualization:\n",
        "\n",
        "*   Matplotlib\n",
        "*   Seaborn\n",
        "\n",
        "**Note**❗: Import only the packages which will be used!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShdIq_X-FBZe"
      },
      "source": [
        "import numpy as np #np is an alias pointing to Numpy\n",
        "import pandas as pd #pd is an alias pointing to Pandas\n",
        "\n",
        "import matplotlib.pyplot as plt #plt is an alias pointing to Matplotlib\n",
        "import seaborn as sns #sns is an alias pointing to Seaborn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Excel spreadsheets\n",
        "import pandas as pd\n",
        "file = 'file.xlsx'\n",
        "data = pd.ExcelFile(file)\n",
        "print(data.sheet_names) # [sheets in the excel file]\n",
        "\n",
        "df1 = data.parse('name of sheet in the excel file') # sheet name, as a string\n",
        "df2 = data.parse(0) # sheet index, as a float\n",
        "\n",
        "# Importing SAS files\n",
        "from sas7bdat import SAS7BDAT\n",
        "with SAS7BDAT('fileName.sas7bdat') as file:    \n",
        "  df_sas = file.to_data_frame()\n",
        "\n",
        "# Importing Stata files\n",
        "data = pd.read_stata('urbanpop.dta')\n",
        "\n",
        "# Importing MATLAB file\n",
        "import scipy.io\n",
        "filename = 'fileName.mat'\n",
        "mat = scipy.io.loadmat(filename)\n",
        "\n",
        "# SQL query\n",
        "from sqlalchemy import create_engine\n",
        "import pandas as pd\n",
        "engine = create_engine('sqlite:///databaseName.sqlite')\n",
        "con = engine.connect()\n",
        "rs = con.execute(\"SELECT * FROM tableName\")\n",
        "df = pd.DataFrame(rs.fetchall())\n",
        "df.columns = rs.keys() # Set the DataFrame column names\n",
        "con.close()\n",
        "\n",
        "# The pandas way to query\n",
        "from sqlalchemy import create_engine\n",
        "import pandas as pd\n",
        "engine = create_engine('sqlite:///databaseName.sqlite')\n",
        "df = pd.read_sql_query(\"SELECT * FROM tableName\", engine)"
      ],
      "metadata": {
        "id": "MX6TI4vSuRpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPZedE1-VOZF"
      },
      "source": [
        "## Read the Dataset\n",
        "Import a dataset often depends on the format of the file (Excel, CSV, text, SPSS, Stata, etc.). These are the most important ways to read the datasets:\n",
        "\n",
        "**Notes**❗: \n",
        "\n",
        "*   CSV stands for comma-separated values.\n",
        "*   You need to pay attention when writing the path of the datatset.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WANR_b4WXZ1E"
      },
      "source": [
        "dataFrame = pd.read_csv('path/file.csv')\n",
        "dataFrame = pd.read_excel('path/file.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pj3TZk2ggJLx"
      },
      "source": [
        "## Inspecting the Data Frame\n",
        "\n",
        "The main intentions of inspecting our data are:\n",
        "\n",
        "*   To have an idea of the size of the dataset.\n",
        "*   To get the data type of each variable in the dataset.\n",
        "*   To identify whether there are missing values in the dataset.\n",
        "\n",
        "And also for another reasons...\n",
        "\n",
        "**Note**❗: shape is Attribute and not methods like head, info and describe.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIRCG9wcgTvL"
      },
      "source": [
        "# Print the head of the Data Frame\n",
        "print(dataFrame.head())\n",
        "\n",
        "# Print information about Data Frame\n",
        "print(dataFrame.info())\n",
        "\n",
        "# Print the shape of Data Frame\n",
        "print(dataFrame.shape)\n",
        "\n",
        "# Print a description of Data Frame\n",
        "print(dataFrame.describe())\n",
        "\n",
        "df.shape # Attribute\n",
        "df.head()# Method"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LA68fxp0izuL"
      },
      "source": [
        "## Sort the Rows in the Data Frame\n",
        "\n",
        "Pandas `sort_values()` method sorts a data frame in Ascending or Descending order of passed Column.\n",
        "\n",
        "**Note**❗: `sort_values()` sorts Ascending by deafult."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZ8Ggm8yi-5l"
      },
      "source": [
        "# One column\n",
        "dataFrame.sort_values(\"col 1\", ascending=True)\n",
        "\n",
        "# Multiple columns\n",
        "dataFrame.sort_values([\"col 1\", \"col 2\"], ascending=[True, False])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3XeNeo-9sSd"
      },
      "source": [
        "## Explicit Indexes\n",
        "\n",
        "*   Columns and Index\n",
        "*   Setting a column as the Index\n",
        "*   Subsetting with Index\n",
        "*   Sort Index\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyvB_bfB_xv0"
      },
      "source": [
        "# Columns and Index\n",
        "dataFrame.columns\n",
        "dataFrame.index\n",
        "\n",
        "# Setting a column as the Index\n",
        "dataFrame_ind = dataFrame.set_index(\"col\")\n",
        "\n",
        "# Subsetting with Index\n",
        "dataFrame[dataFrame[\"col\"].isin([\"row 1\", \"row 2\"])] # First way\n",
        "dataFrame.loc[[\"row 1\", \"row 2\"]] # Second way\n",
        "\n",
        "# Sort Index\n",
        "dataFrame_index = dataFrame.set_index([\"col 1\", \"col 2\"])\n",
        "dataFrame_index.sort_index(level=[\"col 1\", \"col 2\"], ascending=[True, False])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MiOl57FBknO"
      },
      "source": [
        "## Slicing and Subsetting\n",
        "\n",
        "*   Slicing columns\n",
        "*   Slicing by dates\n",
        "*   Subsetting by row/column number\n",
        "*   Subsetting with conditions\n",
        "*   Subsetting rows by categorical variables\n",
        "*   Adding a new column\n",
        "*   Writing to CSV-File\n",
        "\n",
        "**Notes**❗:\n",
        "\n",
        "*   The Data frame should be sorted before slicing.\n",
        "*  **i**loc: i for integer\n",
        "*   Logical Operators in Pandas are (&, | and ~)\n",
        "*   The parentheses (...) is **important**❗\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rfz3fyEhCbtm"
      },
      "source": [
        "# Slicing columns\n",
        "dataFrame_sorted.loc[:, \"col_index 1\":\"col_index 2\"]\n",
        "\n",
        "# Slicing by date\n",
        "dataFrame_sorted.loc[\"yyyy-mm-dd\":\"yyyy-mm-dd\"]\n",
        "\n",
        "# Subsetting by row/column number\n",
        "dataFrame.iloc[3:6, 1:5])\n",
        "\n",
        "# Subsetting with conditions\n",
        "SubSet = dataFrame[(dataFrame['col 1']<1000)& (dataFrame['col 2'] == 'value in col 2')]\n",
        "\n",
        "# Subsetting rows by categorical variables\n",
        "listName = [\"value 1\", \"value 2\", \"value 3\", \"value 4\"] # List of values in a column\n",
        "SubSet = dataFrame[dataFrame[\"col\"].isin(listName)]\n",
        "\n",
        "# Adding a new column\n",
        "dataFrame[\"new column\"] = dataFrame[\"col 1 with integer values\"] / dataFrame[\"col 2 with integer values\"] \n",
        "\n",
        "# Writing to CSV-File\n",
        "dataFrame.to_csv(\"dataFrame_with_new_column.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHHY0A92Mnt_"
      },
      "source": [
        "## Visualizing the Data\n",
        "\n",
        "\n",
        "\n",
        "*   Matplotlib\n",
        "*   Putting two or more data frame in one Plot\n",
        "*   Adding markers\n",
        "*   Setting the line style\n",
        "*   Choosing color\n",
        "*   Customizing the axes labels\n",
        "*   Adding a title\n",
        "*   Small multiples with plt.subplots\n",
        "*   Zooming in on a decade\n",
        "*   Zooming in on one year\n",
        "*   Using twin axes\n",
        "*   Coloring the ticks\n",
        "*   A function that plots time-series\n",
        "*   Adding arrows to annotation\n",
        "*   Rotate the tick labels\n",
        "*   Adding a legend\n",
        "*   Adding error bars to bar charts\n",
        "*   Choosing a style\n",
        "*   Figure Size\n",
        "*   Using Matplotlib for geospatial data\n",
        "*   Seaborn example gallery\n",
        "*   Histograms\n",
        "*   Barplots\n",
        "*   Lineplots\n",
        "*   Scatterplots\n",
        "*   Boxplot **(Comparison)**\n",
        "*   Pairplot\n",
        "*   Saving the figure to file\n",
        "\n",
        "**Notes**❗:\n",
        "\n",
        "* Adjust the number of bars, or bins, using the **\"bins\"** argument. Increasing or decreasing this can give us a better idea of what the distribution looks like.\n",
        "\n",
        "*  Pairplot will pair every variable in the data set to another one and give an overview of how they affect each other.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7I00GuaM97A"
      },
      "source": [
        "# Matplotlib\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(dataFrame[\"colName\"], dataFrame[\"colName\"])\n",
        "\n",
        "# Putting two or more data frame in one Plot\n",
        "ax.plot(dataFrame1[\"colName\"], dataFrame1[\"colName\"])\n",
        "ax.plot(dataFrame2[\"colName\"], dataFrame2[\"colName\"])\n",
        "\n",
        "# Adding markers\n",
        "ax.plot(dataFrame1[\"colName\"], dataFrame1[\"colName\"], marker=\"o\")\n",
        "ax.plot(dataFrame2[\"colName\"], dataFrame2[\"colName\"], marker=\"v\")\n",
        "\n",
        "# Setting the line style\n",
        "ax.plot(dataFrame[\"colName\"], dataFrame[\"colName\"], marker=\"v\", linestyle=\"--\")\n",
        "ax.plot(dataFrame[\"colName\"], dataFrame[\"colName\"], marker=\"v\", linestyle=\"None\")\n",
        "\n",
        "# Choosing color \n",
        "ax.plot(dataFrame[\"colName\"], dataFrame[\"colName\"], marker=\"v\", linestyle=\"--\", color=\"r\") # r for red and b for blue\n",
        "\n",
        "# Customizing the axes labels\n",
        "ax.set_xlabel(\"nameXLabel\")\n",
        "ax.set_ylabel(\"nameYLabel\")\n",
        "\n",
        "# Adding a title\n",
        "ax.set_title(\"nameTitle\")\n",
        "\n",
        "# Small multiples with plt.subplots\n",
        "fig, ax = plt.subplots(3, 2) # For example 3 rows and 2 columns\n",
        "\n",
        "ax[0, 0].plot(dataFrame[\"colName\"], dataFrame[\"colName\"], marker=\"v\", linestyle=\"--\", color=\"r\") # ax[0, 0] The first row and first column\n",
        "ax[0, 1].plot(dataFrame[\"colName\"], dataFrame[\"colName\"], marker=\"v\", linestyle=\"--\", color=\"r\") # ax[0, 1] The first row and second column\n",
        "\n",
        "# Zooming in on a decade\n",
        "seventies = dataFrame[\"1970-01-01\":\"1979-12-31\"] # Example\n",
        "\n",
        "ax.plot(seventies.index, seventies['colName'])\n",
        "\n",
        "# Zooming in on one year\n",
        "fifty_nine = dataFrame[\"1959-01-01\":\"1959-12-31\"]\n",
        "ax.plot(fifty_nine.index, fifty_nine['colName'])\n",
        "\n",
        "# Using twin axes\n",
        "ax.plot(dataFrame.index, dataFrame['colName1'])\n",
        "ax2 = ax.twinx()\n",
        "ax2.plot(dataFrame.index, dataFrame[\"colName2\"])\n",
        "\n",
        "# Coloring the ticks\n",
        "ax.tick_params('y', colors='blue')\n",
        "ax2.tick_params('y', colors='red')\n",
        "\n",
        "# A function that plots time-series\n",
        "def plot_timeseries(axes, x, y, color, xlabel, ylabel):  \n",
        "  axes.plot(x, y, color=color)  \n",
        "  axes.set_xlabel(xlabel)  \n",
        "  axes.set_ylabel(ylabel, color=color)  \n",
        "  axes.tick_params('y', colors=color)\n",
        "\n",
        "# Adding arrows to annotation\n",
        "ax2.annotate(\">1 degree\", xy=(pd.Timestamp('2017-10-05'), 1), xytext=(pd.Timestamp('2007-09-04'), -0.2), arrowprops={\"arrowstyle\":\"->\", \"color\":\"gray\"})\n",
        "\n",
        "# Rotate the tick labels\n",
        "ax.set_xticklabels(DataFrame.index, rotation=90)\n",
        "\n",
        "# Adding a legend\n",
        "ax.legend()\n",
        "\n",
        "# Adding error bars to bar charts\n",
        "ax.bar(\"nameLabel\", DataFrame1[\"colName\"].mean(), yerr=DataFrame1[\"colName\"].std())\n",
        "ax.bar(\"nameLabel\", DataFrame2[\"colName\"].mean(), yerr=DataFrame2[\"colName\"].std())\n",
        "\n",
        "# Choosing a style\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.style.use(\"bmh\")\n",
        "plt.style.use(\"seaborn-colorblind\")\n",
        "\n",
        "# Figure Size\n",
        "fig.set_size_inches([6, 4]) # Examle 6 width 4 height\n",
        "\n",
        "# Using Matplotlib for geospatial data\n",
        "# https://scitools.org.uk/cartopy/docs/latest/\n",
        "\n",
        "# Seaborn example gallery\n",
        "# Pandas + Matplotlib = Seaborn\n",
        "# https://seaborn.pydata.org/examples/index.html\n",
        "\n",
        "\n",
        "# Histograms\n",
        "dataFrame[\"col\"].hist()\n",
        "dataFrame[\"col\"].hist(bins=30)\n",
        "\n",
        "dog_pack[dog_pack[\"col 1\"]==\"value in col 1\"][\"col 2\"].hist(alpha=0.7)\n",
        "dog_pack[dog_pack[\"col 1\"]==\"value in col 1\"][\"col 2\"].hist(alpha=0.7)\n",
        "plt.legend([\"value in col 1\", \"value in col 1\"])\n",
        "\n",
        "\n",
        "# Barplots\n",
        "dataFrame.plot(kind=\"bar\", title=\"Title of the Plot\")\n",
        "\n",
        "# Lineplots\n",
        "dataFrame.plot(x=\"col 1\", y=\"col 2\", kind=\"line\")\n",
        "\n",
        "# Scatterplots\n",
        "dataFrame.plot(x=\"col 1\", y=\"col 2\", kind=\"scatter\")\n",
        "\n",
        "sns.scatterplot(x='col 1', \n",
        "                y='col 2',\n",
        "                hue='col 3', # This will be plotted in different colors.\n",
        "                data=dataFrame)\n",
        "\n",
        "plt.show() # To show the Plot\n",
        "\n",
        "# Boxplot\n",
        "sns.boxplot(x='col 1', \n",
        "            y='col 2',\n",
        "            hue='col 3', # This will be plotted in different colors.\n",
        "            data=dataFrame)\n",
        "\n",
        "# Pairplot\n",
        "sns.pairplot(dataFrame, hue='col'))\n",
        "\n",
        "# Saving the figure to file\n",
        "fig.savefig(\"nameImage.png\", quality=50, dpi=300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Visualization using Seaborn\n",
        "\n",
        "> Works well with `pandas` data structures\n",
        "\n",
        "> Built on top of `matplotlib`\n",
        "\n",
        "\n",
        "---\n",
        "**Difference between Scatter plots, Line plots Count/Bar plots:**\n",
        "\n",
        "*   Scaerplots: Each plot point is an independent observation\n",
        "*   Lineplots: Each plot point represents the same \"thing\", typically tracked\n",
        "over time\n",
        "*   Count/Bar plots: Comparisons between groups\n",
        "*   Boxplot: Shows the distribution of quantitative data, See median, spread, skewness, and outliers and Facilitates comparisons between groups\n",
        "---\n",
        "\n",
        "*   Scatter plot\n",
        "*   Count plot\n",
        "*   Relational plot\n",
        "*   Subplots in columns\n",
        "*   Subplots in rows\n",
        "*   Subplots in rows and columns\n",
        "*   Ordering columns\n",
        "*   Subgroups with point size\n",
        "*   Line plot\n",
        "*   countplot() vs. catplot()\n",
        "*   Boxplot\n",
        "*   Figure style\n",
        "*   Changing the palette: Figure \"palette\" changes the color of the main elements of theplot\n",
        "*   Changing the scale ofthe plot elements and labels\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FGvS-KWr2vHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hue_colors = {\"value1\": \"black\", \"value2\": \"red\"} # For example black and red\n",
        "\n",
        "# Scatter plot\n",
        "sns.scatterplot(x=\"colName\", y=\"colName\", data=dataFrame, hue=colName, hue_order=[value1, value2], palette=hue_colors) \n",
        "\n",
        "# Count plot\n",
        "sns.countplot(x=\"colName\", data=dataFrame, hue=colName)\n",
        "\n",
        "# Relation plot\n",
        "sns.relplot(x=\"colName\", y=\"colName\", data=dataFrame, kind=\"scatter\")\n",
        "\n",
        "# Subplots in columns\n",
        "sns.relplot(x=\"colName\", y=\"colName\", data=dataFrame, kind=\"scatter\", col=\"namePlot\")\n",
        "\n",
        "# Subplots in rows\n",
        "sns.relplot(x=\"colName\", y=\"colName\", data=dataFrame, kind=\"scatter\", row=\"namePlot\")\n",
        "\n",
        "# Subplots in rows and columns\n",
        "sns.relplot(x=\"colName\", y=\"colName\", data=dataFrame, kind=\"scatter\", col=\"namePlot\", row=\"namePlot\")\n",
        "\n",
        "# Ordering columns\n",
        "sns.relplot(x=\"colName\", y=\"colName\", data=dataFrame, kind=\"scatter\", col=\"namePlot\", col_order=[\"\", \"\", \"\"])\n",
        "\n",
        "# Subgroups with point size\n",
        "sns.relplot(x=\"colName\", y=\"colName\", data=dataFrame, kind=\"scatter\", size=\"size\", hue=\"size\")\n",
        "\n",
        "# Line plot\n",
        "sns.relplot(x=\"colName1\", y=\"colName2\", data=dataFrame, kind=\"line\", style=\"\", hue=\"\", markers=True, dashes=False, ci=\"sd\") # sd for interval with standarddeviation\n",
        "\n",
        "# countplot() vs. catplot()\n",
        "sns.countplot(x=\"colName1\", data=dataFrame)\n",
        "\n",
        "sns.catplot(x=\"colName1\", data=dataFrame, kind=\"count\", order=category_order)\n",
        "\n",
        "# Boxplot\n",
        "g = sns.catplot(x=\"colName1\", y=\"colName2\", data=tips, kind=\"box\", order=[\"\", \"\"], sym=\"\") # Omitting the outlier susing `sym`\n",
        "\n",
        "# Figure style\n",
        "sns.set_style(\"whitegrid\") # \"white\", \"dark\", \"whitegrid\", \"darkgrid\", \"ticks\"\n",
        "\n",
        "# Changing the palette\n",
        "sns.set_palette(\"RdBu\")\n",
        "\n",
        "# Changing the scale ofthe plot elements and labels\n",
        "sns.set_context(\"talk\") #\"paper\",\"notebook\",\"talk\",\"poster\""
      ],
      "metadata": {
        "id": "s3Q0VuF13_Hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FuZVs0TPmgP"
      },
      "source": [
        "## Missing Values\n",
        "\n",
        "*   Detecting missing values\n",
        "*   Detecting any missing values\n",
        "*   Counting missing values\n",
        "*   Removing missing values\n",
        "*   Replacing missing values\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMP3yMwTP5yJ"
      },
      "source": [
        "# Detecting missing values\n",
        "dataFrame.isna() # It returns True or False\n",
        "\n",
        "# Detecting any missing values\n",
        "dataFrame.isna().any()\n",
        "\n",
        "# Counting missing values\n",
        "dataFrame.isna().sum()\n",
        "\n",
        "# Removing missing values\n",
        "dataFrame.dropna()\n",
        "\n",
        "# Replacing missing values\n",
        "dogs.fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7u_cwMdSWhtj"
      },
      "source": [
        "## Important Defentions\n",
        "\n",
        "### KPI: \n",
        "\n",
        "> KPI (Key Performance Indicator) is a type of performance measurement. KPIs evaluate the success of an organization or of a particular activity (such as projects, programs, products and other initiatives) in which it engages.\n",
        "\n",
        "Depending on the project you are working with it could be:\n",
        "*  number of new customers per month\n",
        "*  sum of the orders value per day\n",
        "*  Net Promoter Score (NPS)\n",
        "\n",
        "And many many more...\n",
        "\n",
        "### Model Bucket:\n",
        "\n",
        "*   Change over time\n",
        "*   **Comparison**\n",
        "*   **Part of a whole**\n",
        "*   **A Correlation**\n",
        "*   **Ranking**\n",
        "*   **Distribution**\n",
        "*   Flows and relationships\n",
        "*   Geospatial\n",
        "\n",
        "### Numerical Data\n",
        "\n",
        "*   Cumulative sum\n",
        "*   Sum\n",
        "*   Median\n",
        "*   Minimum\n",
        "*   Maximum\n",
        "*   Standard deviation\n",
        "*   Quantil \n",
        "*   Mode\n",
        "*   Count Values\n",
        "*   Variance\n",
        "\n",
        "### APIs and Data Structures\n",
        "\n",
        "> API is the acronym for Application Programming Interface, which is a software intermediary that allows two applications to talk to each other. Each time you use an app like Facebook, send an instant message, or check the weather on your phone, you're using an API.\n",
        "\n",
        "\n",
        "*   What kind of data can you get from the API?\n",
        "*   Does the data contain Lists? What is the content of these Lists?\n",
        "*   Does the data contain Dictionaries? What is the content of the Dictionaries?\n",
        "\n",
        "### Business Intelligence tools\n",
        "\n",
        "*  **Tableau**\n",
        "*  **Looker**\n",
        "*  Metabase\n",
        "*  Periscope\n",
        "*  Plotly Dash\n",
        "*  Datapine\n",
        "*  Zoho Analytics\n",
        "*  **PowerBI**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-otVX5-CilR"
      },
      "source": [
        "# Median\n",
        "dataFrame[\"col\"].median()\n",
        "\n",
        "# Mode\n",
        "dataFrame.mode()\n",
        "\n",
        "# Minimum\n",
        "dataFrame[\"col\"].min()\n",
        "\n",
        "# Maximum\n",
        "dataFrame[\"col\"].max()\n",
        "\n",
        "# Unbiased Variance\n",
        "dataFrame.var() # unbiased variance\n",
        "\n",
        "# Standard deviation\n",
        "dataFrame[\"col\"].std()\n",
        "\n",
        "# Sum\n",
        "dataFrame.sum()\n",
        "\n",
        "# Quantil\n",
        "dataFrame.quantile()\n",
        " \n",
        "# Count Values\n",
        "dataFrame[\"col\"].value_counts(sort=True) # Sort is False by default."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrxiRBWxw3ba"
      },
      "source": [
        "## Grouped Summary Statistics\n",
        "\n",
        "*   Grouped summaries\n",
        "*   Multiple grouped summaries\n",
        "*   Groupingby multiple variables\n",
        "*   Many groups, many summaries\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vd_IMOXGxO4L"
      },
      "source": [
        "# Grouped summaries\n",
        "dataFrame.groupby(\"col 1\")[\"col 2\"].mean() # min(), max() or sum can be used instead of mean()\n",
        "\n",
        "# Multiple grouped summaries\n",
        "dataFrame.groupby(\"col 1\")[\"col 2\"].agg([min, max, sum])\n",
        "\n",
        "#Groupingby multiple variables\n",
        "dataFrame.groupby([\"col 1\", \"col 2\"])[\"col 3\"].mean()\n",
        "\n",
        "# Many groups,many summaries\n",
        "dataFrame.groupby([\"col 1\", \"col 2\"])[[\"col 3\", \"col 4\"]].mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EknSXYiIdQzq"
      },
      "source": [
        "## Selecting Data with Query\n",
        "\n",
        "*   The .`query()` Method\n",
        "*   Querying on  asingle condition\n",
        "*   Querying on a multiple conditions, \"and\", \"or\"\n",
        "*   Using `.query()` to select text\n",
        "\n",
        "**Note**❗: The `.query()` Method accepts an input string: \n",
        " \n",
        "\n",
        "*   Input string used to determine what rows are returned\n",
        "*   Input string similar to statement after **WHERE** clause in **SQL** statement\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPjwOEZNdtkw"
      },
      "source": [
        "# The .query() Method\n",
        "dataFrame.query('SOME SELECTION STATEMENT')\n",
        "\n",
        "# Querying on asingle condition\n",
        "dataFrame.query('col >= int')\n",
        "\n",
        "# Querying on a multiple conditions, \"and\", \"or\"\n",
        "dataFrame.query('col 1 > int and col 2 < int')\n",
        "dataFrame.query('col 1 > int or col 2 < int')\n",
        "\n",
        "# Using .query() to select text\n",
        "dataFrame.query('col 1==\"value(string)\" or (col 1==\"value(string)\" and col 2 < int)')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}